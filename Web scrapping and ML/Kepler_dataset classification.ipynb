{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "697fa78f",
   "metadata": {},
   "source": [
    "# Create an ML algorithm to classify the planets as Candidate/False positive/Confirmed etc based on the  column “koi_disposition”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4f74759c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns present in the dataframe:\n",
      "Index(['kepid', 'kepoi_name', 'kepler_name', 'koi_disposition',\n",
      "       'koi_pdisposition', 'koi_score', 'koi_fpflag_nt', 'koi_fpflag_ss',\n",
      "       'koi_fpflag_co', 'koi_fpflag_ec', 'koi_period', 'koi_period_err1',\n",
      "       'koi_period_err2', 'koi_time0bk', 'koi_time0bk_err1',\n",
      "       'koi_time0bk_err2', 'koi_impact', 'koi_impact_err1', 'koi_impact_err2',\n",
      "       'koi_duration', 'koi_duration_err1', 'koi_duration_err2', 'koi_depth',\n",
      "       'koi_depth_err1', 'koi_depth_err2', 'koi_prad', 'koi_prad_err1',\n",
      "       'koi_prad_err2', 'koi_teq', 'koi_teq_err1', 'koi_teq_err2', 'koi_insol',\n",
      "       'koi_insol_err1', 'koi_insol_err2', 'koi_model_snr', 'koi_tce_plnt_num',\n",
      "       'koi_tce_delivname', 'koi_steff', 'koi_steff_err1', 'koi_steff_err2',\n",
      "       'koi_slogg', 'koi_slogg_err1', 'koi_slogg_err2', 'koi_srad',\n",
      "       'koi_srad_err1', 'koi_srad_err2', 'ra', 'dec', 'koi_kepmag'],\n",
      "      dtype='object')\n",
      "Accuracy: 0.9843178254051228\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load data using csv\n",
    "kepler_data = pd.read_csv(\"kepler_data-2.csv\")\n",
    "\n",
    "print(\"Columns present in the dataframe:\")\n",
    "print(kepler_data.columns)\n",
    "\n",
    "# Droping the unnecessary columns\n",
    "kepler_data.drop(columns=['kepoi_name', 'koi_teq_err1', 'koi_teq_err2'], inplace=True)\n",
    "\n",
    "\n",
    "X = kepler_data.drop(columns=['koi_disposition'])\n",
    "y = kepler_data['koi_disposition']\n",
    "\n",
    "# Spliting train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#preprocessing of data\n",
    "numeric_columns = X.select_dtypes(include=['float64']).columns\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "# fitting of traning data\n",
    "X_train_numeric = numeric_transformer.fit_transform(X_train[numeric_columns])\n",
    "X_test_numeric = numeric_transformer.transform(X_test[numeric_columns])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "X_train_categorical = categorical_transformer.fit_transform(X_train[categorical_columns])\n",
    "X_test_categorical = categorical_transformer.transform(X_test[categorical_columns])\n",
    "X_train_processed = np.hstack((X_train_numeric, X_train_categorical.toarray()))\n",
    "X_test_processed = np.hstack((X_test_numeric, X_test_categorical.toarray()))\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_processed, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_processed)\n",
    "\n",
    "# Accuracy Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1a1286d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CANDIDATE' 'FALSE POSITIVE']\n"
     ]
    }
   ],
   "source": [
    "# Check unique values in 'koi_pdisposition'\n",
    "print(kepler_df['koi_pdisposition'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fdb3aa77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values for column 'kepid': [10797460 10811496 10848459 ... 10147276 10155286 10156110]\n",
      "Unique values for column 'kepoi_name': ['K00752.01' 'K00752.02' 'K00753.01' ... 'K07987.01' 'K07988.01'\n",
      " 'K07989.01']\n",
      "Unique values for column 'koi_disposition': [ 1  0 -1]\n",
      "Unique values for column 'koi_pdisposition': ['CANDIDATE' 'FALSE POSITIVE']\n",
      "Unique values for column 'koi_score': [1.        0.969     0.        0.992     0.811     0.998     0.98\n",
      " 0.971     0.4808294 0.978     0.014     0.999     0.993     0.871\n",
      " 0.773     0.989     0.952     0.994     0.053     0.95      0.745\n",
      " 0.99      0.995     0.037     0.006     0.996     0.997     0.878\n",
      " 0.876     0.985     0.942     0.912     0.974     0.959     0.987\n",
      " 0.983     0.573     0.986     0.635     0.966     0.415     0.228\n",
      " 0.957     0.92      0.973     0.975     0.953     0.704     0.949\n",
      " 0.965     0.632     0.752     0.945     0.765     0.815     0.931\n",
      " 0.711     0.881     0.758     0.001     0.848     0.884     0.557\n",
      " 0.008     0.976     0.829     0.991     0.046     0.964     0.762\n",
      " 0.695     0.821     0.913     0.982     0.968     0.934     0.894\n",
      " 0.875     0.885     0.961     0.729     0.921     0.907     0.545\n",
      " 0.098     0.91      0.857     0.483     0.939     0.754     0.68\n",
      " 0.436     0.117     0.96      0.002     0.677     0.49      0.041\n",
      " 0.988     0.005     0.085     0.979     0.909     0.383     0.867\n",
      " 0.927     0.087     0.936     0.896     0.808     0.935     0.981\n",
      " 0.285     0.003     0.565     0.933     0.086     0.242     0.984\n",
      " 0.855     0.82      0.748     0.944     0.464     0.809     0.938\n",
      " 0.977     0.802     0.889     0.972     0.406     0.004     0.956\n",
      " 0.924     0.488     0.903     0.365     0.761     0.759     0.693\n",
      " 0.922     0.186     0.926     0.733     0.738     0.133     0.9\n",
      " 0.838     0.331     0.603     0.85      0.243     0.899     0.951\n",
      " 0.4       0.862     0.861     0.937     0.359     0.879     0.967\n",
      " 0.46      0.854     0.371     0.404     0.269     0.011     0.013\n",
      " 0.056     0.962     0.15      0.036     0.007     0.059     0.199\n",
      " 0.97      0.305     0.749     0.526     0.859     0.485     0.898\n",
      " 0.407     0.897     0.895     0.919     0.816     0.649     0.582\n",
      " 0.651     0.918     0.427     0.911     0.28      0.387     0.294\n",
      " 0.054     0.932     0.943     0.833     0.893     0.836     0.01\n",
      " 0.424     0.742     0.015     0.743     0.883     0.94      0.868\n",
      " 0.958     0.274     0.739     0.757     0.717     0.947     0.93\n",
      " 0.709     0.963     0.73      0.785     0.024     0.954     0.948\n",
      " 0.063     0.276     0.782     0.797     0.354     0.901     0.606\n",
      " 0.804     0.803     0.887     0.844     0.941     0.052     0.946\n",
      " 0.786     0.755     0.614     0.929     0.828     0.917     0.877\n",
      " 0.073     0.476     0.915     0.905     0.882     0.799     0.892\n",
      " 0.394     0.87      0.858     0.768     0.254     0.508     0.378\n",
      " 0.351     0.552     0.59      0.88      0.673     0.189     0.047\n",
      " 0.174     0.425     0.676     0.122     0.374     0.559     0.343\n",
      " 0.812     0.217     0.598     0.471     0.498     0.57      0.955\n",
      " 0.866     0.146     0.04      0.029     0.258     0.089     0.819\n",
      " 0.69      0.246     0.384     0.017     0.563     0.368     0.766\n",
      " 0.553     0.376     0.813     0.193     0.529     0.886     0.141\n",
      " 0.491     0.027     0.772     0.675     0.928     0.691     0.284\n",
      " 0.76      0.273     0.872     0.325     0.767     0.147     0.402\n",
      " 0.019     0.097     0.514     0.1       0.196     0.307     0.775\n",
      " 0.08      0.638     0.536     0.914     0.298     0.77      0.016\n",
      " 0.364     0.554     0.409     0.571     0.579     0.7       0.528\n",
      " 0.741     0.84      0.044     0.125     0.694     0.012     0.493\n",
      " 0.446     0.665     0.8       0.806     0.831     0.817     0.686\n",
      " 0.842     0.405     0.835     0.655     0.521     0.851     0.791\n",
      " 0.191     0.904     0.348     0.607     0.129     0.156     0.334\n",
      " 0.281     0.506     0.619     0.794     0.116     0.753     0.072\n",
      " 0.255     0.798     0.52      0.625     0.083     0.837     0.198\n",
      " 0.622     0.556     0.065     0.333     0.777     0.744     0.736\n",
      " 0.923     0.502     0.23      0.414     0.865     0.78      0.17\n",
      " 0.216     0.823     0.413     0.795     0.825     0.265     0.103\n",
      " 0.834     0.381     0.864     0.846     0.113     0.018     0.708\n",
      " 0.318     0.022     0.362     0.179     0.048     0.916     0.656\n",
      " 0.322     0.077     0.925     0.45      0.329     0.849     0.522\n",
      " 0.469     0.09      0.719     0.771     0.67      0.692     0.135\n",
      " 0.139     0.253     0.776     0.74      0.393     0.592     0.484\n",
      " 0.169     0.02      0.783     0.86      0.618     0.602     0.358\n",
      " 0.009     0.863     0.323     0.207     0.805     0.475     0.636\n",
      " 0.873     0.045     0.084     0.234     0.874     0.132     0.448\n",
      " 0.856     0.349     0.465     0.495     0.025     0.181     0.89\n",
      " 0.131     0.188     0.908     0.256     0.558     0.902     0.523\n",
      " 0.061     0.633     0.609     0.627     0.233     0.852     0.136\n",
      " 0.134     0.175     0.643     0.088     0.492     0.562     0.654\n",
      " 0.716     0.814     0.507     0.44      0.13      0.313     0.568\n",
      " 0.275     0.56      0.648     0.176     0.789     0.511     0.185\n",
      " 0.467     0.832     0.37      0.433     0.534     0.094     0.479\n",
      " 0.705     0.049     0.737     0.292     0.616     0.629     0.612\n",
      " 0.301     0.034     0.826     0.021     0.644     0.128     0.309\n",
      " 0.429     0.869     0.496     0.137     0.441     0.784     0.149\n",
      " 0.283     0.847     0.672     0.112     0.55      0.337     0.229\n",
      " 0.315     0.718     0.888     0.801     0.397     0.668     0.827\n",
      " 0.184     0.118     0.386     0.277     0.212     0.669     0.701\n",
      " 0.685     0.779     0.126     0.206     0.721     0.235     0.039\n",
      " 0.303     0.532     0.891     0.61      0.167     0.756     0.452\n",
      " 0.763     0.057     0.658     0.646     0.347     0.79      0.788\n",
      " 0.267     0.035     0.769     0.451     0.078     0.231     0.324\n",
      " 0.074     0.168     0.157     0.266     0.05      0.224     0.043\n",
      " 0.079     0.075     0.223     0.108     0.102     0.163     0.092\n",
      " 0.731     0.096     0.259     0.444     0.22      0.114     0.03\n",
      " 0.208     0.251     0.262     0.75      0.247     0.071     0.202\n",
      " 0.159     0.363     0.11      0.067     0.487     0.066     0.525\n",
      " 0.513     0.312     0.106     0.272     0.311     0.107     0.291\n",
      " 0.388     0.127     0.293     0.238     0.578     0.12      0.104\n",
      " 0.289     0.038     0.335     0.839     0.197     0.153     0.541\n",
      " 0.449     0.702     0.382     0.042     0.252     0.204     0.203\n",
      " 0.121     0.34      0.295     0.115     0.19      0.152     0.058\n",
      " 0.416     0.316     0.356     0.843     0.3       0.519     0.497    ]\n",
      "Unique values for column 'koi_fpflag_nt': [  0   1 465]\n",
      "Unique values for column 'koi_fpflag_ss': [0 1]\n",
      "Unique values for column 'koi_fpflag_co': [0 1]\n",
      "Unique values for column 'koi_fpflag_ec': [0 1]\n",
      "Unique values for column 'koi_period': [  9.48803557  54.4183827   19.89913995 ...   0.68140161 333.486169\n",
      "   4.85603482]\n",
      "Unique values for column 'koi_period_err1': [2.775e-05 2.479e-04 1.494e-05 ... 1.780e-05 2.434e-06 4.235e-03]\n",
      "Unique values for column 'koi_period_err2': [-2.775e-05 -2.479e-04 -1.494e-05 ... -1.780e-05 -2.434e-06 -4.235e-03]\n",
      "Unique values for column 'koi_time0bk': [170.53875  162.51384  175.850252 ... 133.00127  132.18175  153.61501 ]\n",
      "Unique values for column 'koi_time0bk_err1': [0.00216  0.00352  0.000581 ... 0.0859   0.0516   0.0763  ]\n",
      "Unique values for column 'koi_time0bk_err2': [-0.00216  -0.00352  -0.000581 ... -0.0859   -0.0516   -0.0763  ]\n",
      "Unique values for column 'koi_impact': [0.146 0.586 0.969 ... 1.052 1.339 0.165]\n",
      "Unique values for column 'koi_impact_err1': [3.180e-01 5.900e-02 5.126e+00 ... 6.859e+00 7.431e+01 5.390e-01]\n",
      "Unique values for column 'koi_impact_err2': [-0.146 -0.443 -0.077 ... -3.631 -2.465 -4.203]\n",
      "Unique values for column 'koi_duration': [2.9575 4.507  1.7822 ... 4.806  3.2221 0.865 ]\n",
      "Unique values for column 'koi_duration_err1': [0.0819 0.116  0.0341 ... 0.804  0.925  0.795 ]\n",
      "Unique values for column 'koi_duration_err2': [-0.0819 -0.116  -0.0341 ... -0.804  -0.925  -0.795 ]\n",
      "Unique values for column 'koi_depth': [  615.8   874.8 10829.  ...    48.5   103.6   639.1]\n",
      "Unique values for column 'koi_depth_err1': [ 19.5  35.5 171.  ...  98.2 219.   72.9]\n",
      "Unique values for column 'koi_depth_err2': [ -19.5  -35.5 -171.  ...  -98.2 -219.   -72.9]\n",
      "Unique values for column 'koi_prad': [ 2.26  2.83 14.6  ... 18.27 29.35 19.3 ]\n",
      "Unique values for column 'koi_prad_err1': [ 0.26  0.32  3.92 ...  2.68 13.71  3.34]\n",
      "Unique values for column 'koi_prad_err2': [ -0.15  -0.19  -1.31 ... -31.99 -10.66 -30.35]\n",
      "Unique values for column 'koi_teq': [ 793.  443.  638. ...   92. 2088. 2218.]\n",
      "Unique values for column 'koi_insol': [  93.59    9.11   39.3  ... 5713.41   22.68  607.42]\n",
      "Unique values for column 'koi_insol_err1': [2.94500e+01 2.87000e+00 3.10400e+01 ... 1.53786e+03 5.67574e+03\n",
      " 6.00390e+02]\n",
      "Unique values for column 'koi_insol_err2': [-1.66500e+01 -1.62000e+00 -1.04900e+01 ... -1.17526e+03 -5.02220e+02\n",
      " -1.83694e+03]\n",
      "Unique values for column 'koi_model_snr': [  35.8   25.8   76.3 ...  301.7 6351.7  453.3]\n",
      "Unique values for column 'koi_tce_plnt_num': [1.         2.         3.         1.24365372 4.         5.\n",
      " 6.         7.         8.        ]\n",
      "Unique values for column 'koi_tce_delivname': ['q1_q17_dr25_tce' 'q1_q16_tce' nan 'q1_q17_dr24_tce']\n",
      "Unique values for column 'koi_steff': [ 5455.  5853.  5805. ... 15896.  4067.  3439.]\n",
      "Unique values for column 'koi_steff_err1': [ 81.         158.         157.         169.         189.\n",
      " 111.          75.          78.          76.         112.\n",
      " 105.         155.         151.         182.         168.\n",
      " 131.         123.         149.          85.          79.\n",
      " 175.         152.         100.         184.          82.\n",
      " 164.          77.         104.         180.         173.\n",
      "  74.         136.         154.         183.         166.\n",
      " 179.          73.         162.         174.         161.\n",
      " 159.         156.          72.         176.          70.\n",
      " 167.         160.          83.          98.          99.\n",
      " 171.         140.         148.          64.         205.\n",
      " 193.         114.         130.         128.         190.\n",
      " 177.         101.          71.         165.         181.\n",
      "  89.         108.         102.         280.         113.\n",
      " 481.         125.         146.          84.         106.\n",
      "  61.         560.         118.          90.         117.\n",
      " 186.         103.         676.         153.         150.\n",
      " 163.         172.         110.         197.         120.\n",
      "  80.          40.          50.         267.         144.63555409\n",
      " 226.          93.         143.          49.         115.\n",
      " 291.         200.         126.         129.         121.\n",
      " 119.         141.         204.         107.         187.\n",
      "  87.         192.          94.         272.         216.\n",
      " 240.         215.         170.         145.         202.\n",
      " 328.         185.         147.         135.          56.\n",
      " 194.          57.         228.         242.          65.\n",
      " 195.         142.          97.           0.         206.\n",
      "  58.          44.         304.          86.         116.\n",
      "  88.          68.         139.         196.          60.\n",
      "  59.         191.         225.         124.         268.\n",
      "  92.         109.         221.         132.         208.\n",
      " 224.         138.         219.          51.         207.\n",
      "  52.          54.         133.          96.         134.\n",
      " 201.          91.         214.          69.         137.\n",
      " 209.          62.         144.         178.         127.\n",
      " 237.         301.         122.         198.         235.\n",
      " 203.         217.         302.         447.          95.\n",
      " 335.         265.         199.         287.          67.\n",
      " 210.         188.         255.         211.         213.\n",
      " 229.         222.         212.         227.         251.\n",
      " 275.         297.          63.         218.         261.\n",
      "  55.         232.         250.         334.         247.\n",
      " 595.         299.         223.         411.         233.\n",
      " 220.          66.         470.         239.         230.\n",
      " 286.         289.         284.         241.          53.\n",
      " 262.         236.          28.          47.         266.\n",
      " 331.         433.         231.          42.          45.\n",
      " 402.         238.         323.         244.          38.\n",
      " 506.         325.          48.         587.         246.\n",
      " 260.         263.          37.          43.          39.\n",
      " 309.         298.         313.         296.         256.\n",
      " 434.         462.         454.         290.         254.\n",
      "  41.         338.          46.         249.         276.\n",
      " 330.        ]\n",
      "Unique values for column 'koi_steff_err2': [  -81.          -176.          -174.          -211.\n",
      "  -232.          -124.           -83.           -78.\n",
      "   -89.          -137.          -117.          -172.\n",
      "  -151.          -200.          -153.          -146.\n",
      "  -123.          -149.           -77.           -79.\n",
      "  -159.          -169.          -111.          -220.\n",
      "   -74.          -152.          -182.          -210.\n",
      "  -115.          -164.          -239.          -192.\n",
      "  -154.          -201.           -82.          -163.\n",
      "   -91.          -173.          -180.          -166.\n",
      "  -168.           -90.          -193.          -156.\n",
      "  -197.           -86.          -167.          -160.\n",
      "   -85.          -120.          -112.          -188.\n",
      "  -178.          -155.          -148.          -226.\n",
      "   -75.          -183.          -205.          -219.\n",
      "  -214.          -171.          -105.          -175.\n",
      "  -103.          -162.26505891     0.          -144.\n",
      "  -142.          -177.           -71.          -136.\n",
      "  -147.          -158.          -101.          -218.\n",
      "  -157.          -133.           -84.          -184.\n",
      "   -73.          -108.          -102.          -229.\n",
      "  -259.          -113.          -189.           -92.\n",
      "  -179.           -96.          -217.          -301.\n",
      "  -130.          -190.           -88.          -416.\n",
      "  -125.          -110.          -265.          -165.\n",
      "  -109.          -161.          -237.          -225.\n",
      "   -80.          -248.          -122.          -230.\n",
      "  -241.          -121.          -326.          -340.\n",
      "  -129.          -118.          -207.          -119.\n",
      "  -104.          -291.          -181.           -69.\n",
      "  -343.          -140.          -100.          -198.\n",
      "  -195.          -206.          -138.           -60.\n",
      "  -116.          -135.          -320.          -287.\n",
      "  -224.          -202.          -131.          -187.\n",
      "  -145.           -57.           -72.          -213.\n",
      "   -94.          -222.          -246.          -467.\n",
      "  -324.          -247.          -412.           -76.\n",
      "  -141.          -143.          -204.          -106.\n",
      "   -66.          -215.           -97.          -263.\n",
      "  -227.          -194.          -712.          -128.\n",
      "  -185.          -236.           -61.          -267.\n",
      "   -87.          -261.           -62.          -304.\n",
      "  -162.          -134.          -264.          -443.\n",
      "  -150.          -170.          -310.           -65.\n",
      "  -107.           -24.          -223.          -457.\n",
      "  -208.          -199.          -191.           -64.\n",
      "  -114.          -313.           -67.          -186.\n",
      "  -212.          -240.          -300.         -1005.\n",
      "  -228.           -98.          -347.          -234.\n",
      "   -95.          -336.          -255.          -250.\n",
      "  -243.          -132.          -216.          -209.\n",
      "  -337.           -58.          -258.          -406.\n",
      "  -231.          -277.          -322.          -203.\n",
      "  -127.          -233.          -314.           -55.\n",
      "  -126.          -251.          -235.          -139.\n",
      "  -196.           -93.          -542.           -70.\n",
      "  -295.          -316.          -452.          -242.\n",
      "  -249.          -279.          -221.           -54.\n",
      "  -325.          -281.           -59.          -260.\n",
      "  -335.           -46.          -268.          -503.\n",
      "  -404.          -366.           -47.          -257.\n",
      "   -37.          -253.          -276.           -68.\n",
      "  -329.          -438.           -51.          -372.\n",
      "  -272.          -368.          -245.          -466.\n",
      "   -42.          -413.          -252.          -286.\n",
      "  -338.          -282.          -278.           -53.\n",
      "  -376.          -283.          -327.          -385.\n",
      "   -44.          -256.          -428.          -273.\n",
      "  -371.          -407.          -305.          -345.\n",
      "  -727.          -332.          -411.          -244.\n",
      "  -822.           -56.          -317.           -50.\n",
      "  -353.          -400.          -331.          -275.\n",
      "  -238.          -285.          -941.          -254.\n",
      "  -414.         -1044.          -319.           -63.\n",
      "  -430.          -434.          -262.          -284.\n",
      "  -342.          -350.          -307.          -318.\n",
      "  -426.          -330.          -312.           -52.\n",
      "  -379.          -380.          -450.          -355.\n",
      "  -266.          -311.          -495.          -478.\n",
      "   -33.         -1733.           -40.          -393.\n",
      "  -398.          -303.          -358.          -334.\n",
      "  -297.          -374.          -391.          -309.\n",
      "  -299.         -1519.          -758.          -408.\n",
      "  -341.          -328.         -1762.          -458.\n",
      "  -302.          -464.          -399.          -451.\n",
      "  -315.          -429.          -298.          -296.\n",
      "  -378.          -530.          -461.          -364.\n",
      "  -469.          -365.          -290.          -288.\n",
      "  -270.          -274.          -271.          -925.\n",
      "  -844.           -25.          -410.           -29.\n",
      "  -306.          -422.          -293.          -370.\n",
      "  -333.          -427.           -99.          -294.\n",
      "  -360.          -396.          -575.           -43.\n",
      "  -403.          -415.           -32.          -357.\n",
      "   -41.        ]\n",
      "Unique values for column 'koi_slogg': [4.467 4.544 4.564 ... 3.952 4.939 2.992]\n",
      "Unique values for column 'koi_slogg_err1': [0.064      0.044      0.053      0.07       0.054      0.182\n",
      " 0.083      0.024      0.033      0.055      0.085      0.072\n",
      " 0.052      0.088      0.065      0.02       0.09       0.098\n",
      " 0.014      0.075      0.034      0.032      0.04       0.121\n",
      " 0.092      0.05       0.11       0.091      0.132      0.153\n",
      " 0.036      0.056      0.063      0.03       0.046      0.022\n",
      " 0.116      0.18       0.012      0.105      0.028      0.027\n",
      " 0.049      0.124      0.039      0.156      0.084      0.126\n",
      " 0.048      0.042      0.137      0.038      0.026      0.066\n",
      " 0.081      0.087      0.029      0.077      0.035      0.01\n",
      " 0.162      0.011      0.062      0.058      0.195      0.018\n",
      " 0.06       0.144      0.023      0.241      0.08       0.225\n",
      " 0.025      0.117      0.104      0.045      0.013      0.21\n",
      " 0.185      0.016      0.076      0.136      0.252      0.019\n",
      " 0.094      0.196      0.037      0.188      0.168      0.051\n",
      " 0.163      0.707      0.352      0.639      0.078      0.12073791\n",
      " 0.198      0.12       0.256      0.293      0.203      0.272\n",
      " 0.128      0.071      0.443      0.135      0.112      0.258\n",
      " 0.145      0.008      0.323      0.13       0.015      0.255\n",
      " 0.3        0.157      0.221      0.248      0.099      0.074\n",
      " 0.171      0.138      0.149      0.587      0.392      0.127\n",
      " 0.217      0.079      0.74       0.186      0.059      0.246\n",
      " 0.067      0.238      0.282      0.52       0.84       0.14\n",
      " 0.175      0.102      0.917      0.031      0.315      0.115\n",
      " 0.832      0.343      0.         0.285      0.22       0.007\n",
      " 0.021      0.101      0.174      0.218      0.264      0.082\n",
      " 0.378      0.093      0.125      0.367      0.512      0.266\n",
      " 0.222      0.148      0.259      0.047      0.432      0.231\n",
      " 0.517      0.1        0.224      0.043      0.108      0.165\n",
      " 0.227      0.068      0.45       0.119      0.376      0.19\n",
      " 0.569      0.28       0.682      0.15       0.368      0.201\n",
      " 0.204      0.143      0.276      0.095      0.155      0.232\n",
      " 0.114      0.111      0.118      0.16       0.103      0.176\n",
      " 0.336      0.009      0.233      0.194      0.158      0.202\n",
      " 0.294      0.458      0.041      0.693      0.57       0.602\n",
      " 0.154      0.504      0.24       0.337      0.167      0.017\n",
      " 0.193      0.535      0.287      0.637      0.304      0.061\n",
      " 0.616      0.208      0.42       0.096      0.292      0.286\n",
      " 0.069      0.17       0.791      0.147      0.704      0.308\n",
      " 0.631      0.209      0.228      0.36       0.247      0.273\n",
      " 0.344      0.189      0.073      0.236      0.27       0.131\n",
      " 0.057      0.405      0.328      0.448      0.277      0.245\n",
      " 0.299      0.425      0.006      0.263      0.322      0.33\n",
      " 0.447      0.214      0.756      0.312      0.416      0.864\n",
      " 0.32       0.192      0.35       0.578      0.319      0.301\n",
      " 0.644      0.253      0.749      0.159      0.351      0.161\n",
      " 0.609      0.345      0.139      0.364      0.496      0.44\n",
      " 0.413      0.134      0.472      0.086      0.306      0.234\n",
      " 0.357      0.584      0.712      0.816      0.278      0.187\n",
      " 0.372      0.676      0.164      0.672      0.26       0.511\n",
      " 0.435      0.396      0.536      0.513      0.87       0.177\n",
      " 0.54       0.665      0.66       0.408      0.169      0.605\n",
      " 0.244      0.518      0.501      0.69       0.097      0.346\n",
      " 0.211      0.455      0.572      0.397      0.402      0.658\n",
      " 0.465      0.338      0.307      0.863      0.567      0.216\n",
      " 0.269      0.243      0.215      0.384      0.325      0.113\n",
      " 0.311      0.624      0.63       0.526      0.152      0.109\n",
      " 0.2        0.467      0.184      0.418      0.651      0.389\n",
      " 0.382      0.495      0.528      0.219      0.446      0.332\n",
      " 0.329      1.005      0.765      0.667      0.493      0.591\n",
      " 0.296      0.302      0.199      0.106      0.237      0.679\n",
      " 1.472      0.428      0.406      0.456      0.391      0.9\n",
      " 0.923      0.585      0.805      0.888      0.904      0.728\n",
      " 0.75       0.568      0.975      0.777      0.7        0.262\n",
      " 0.133      0.398      0.848      0.205      0.907      0.553\n",
      " 0.56       0.671      1.24       0.442      0.434      0.142\n",
      " 0.58       0.623      0.818      0.968      0.772      0.519\n",
      " 0.254      0.483      0.349      0.409      0.773      0.998\n",
      " 0.34       0.23       0.697      1.192      0.808      0.574\n",
      " 0.39       0.48       0.353      0.617      0.598      0.358\n",
      " 0.399      0.261      0.229      0.339      0.191      0.354\n",
      " 0.462      0.381      0.375      0.459      0.347      0.107\n",
      " 0.242      0.207      0.628      0.183      0.539      0.122\n",
      " 0.197      0.348      0.309      0.482      0.333      0.657\n",
      " 0.936      0.25       0.527      0.451      0.179      0.604\n",
      " 0.305      0.581      0.96       0.552      0.688      0.792\n",
      " 0.318      0.275      0.271      0.427      0.542      0.298\n",
      " 0.893      0.341      0.412      0.235      1.232      0.689\n",
      " 0.385      0.386      0.784      0.849      0.355      0.284\n",
      " 0.522      0.878      0.546      0.327      0.123      0.422\n",
      " 0.647      0.303      0.445      0.289      0.742      0.239\n",
      " 0.297      0.77       0.251      0.477      0.129      0.503\n",
      " 0.595      0.821      0.274      0.141      0.151      0.49\n",
      " 0.944      0.436      0.146      0.488      0.521      0.664\n",
      " 0.331      0.745      0.705      0.38       0.172      0.884\n",
      " 0.283      0.213      0.31       0.735      0.226      0.817\n",
      " 0.727      0.476      0.51       0.807      0.544      0.424\n",
      " 0.608      0.267      0.366      0.441      0.892      0.656\n",
      " 0.403      0.464      0.696      0.78       0.629      0.824\n",
      " 0.872      0.99       0.474      0.72       0.515      0.752\n",
      " 0.653      0.395      0.612      0.912      0.181      0.363\n",
      " 0.468      0.288      0.586      0.819      0.856      0.532\n",
      " 1.057      0.592     ]\n",
      "Unique values for column 'koi_slogg_err2': [-0.096      -0.176      -0.168      -0.21       -0.229      -0.098\n",
      " -0.028      -0.024      -0.027      -0.045      -0.114      -0.048\n",
      " -0.208      -0.072      -0.035      -0.056      -0.06       -0.014\n",
      " -0.02       -0.136      -0.16       -0.12       -0.217      -0.099\n",
      " -0.115      -0.15       -0.11       -0.169      -0.108      -0.187\n",
      " -0.144      -0.07       -0.196      -0.117      -0.084      -0.022\n",
      " -0.105      -0.198      -0.064      -0.195      -0.161      -0.128\n",
      " -0.186      -0.216      -0.275      -0.104      -0.103      -0.112\n",
      " -0.083      -0.192      -0.031      -0.1        -0.152      -0.18\n",
      " -0.081      -0.094      -0.204      -0.097      -0.044      -0.123\n",
      " -0.018      -0.221      -0.025      -0.039      -0.163      -0.162\n",
      " -0.188      -0.272      -0.041      -0.184      -0.063      -0.085\n",
      " -0.2        -0.154      -0.032      -0.016      -0.224      -0.212\n",
      " -0.09       -0.052      -0.036      -0.182      -0.13       -0.088\n",
      " -0.075      -0.202      -0.03       -0.04       -0.043      -0.055\n",
      " -0.189      -0.102      -0.08       -0.201      -0.175      -0.049\n",
      " -0.156      -0.213      -0.101      -0.135      -0.17       -0.27\n",
      " -0.264      -0.303      -0.071      -0.14316051 -0.132      -0.203\n",
      " -0.087      -0.148      -0.137      -0.211      -0.145      -0.008\n",
      " -0.181      -0.033      -0.165      -0.414      -0.263      -0.119\n",
      " -0.078      -0.121      -0.19       -0.051      -0.291      -0.127\n",
      " -0.054      -0.093      -0.234      -0.159      -0.113      -0.233\n",
      " -0.268      -0.173      -0.125      -0.131      -0.038      -0.298\n",
      " -0.164      -0.143      -0.26       -0.153      -0.185      -0.095\n",
      " -0.122      -0.077      -0.578      -0.327      -0.232      -0.017\n",
      " -0.311      -0.147      -0.304      -0.748       0.         -0.166\n",
      " -0.065      -0.22       -0.269      -0.015      -0.061      -0.178\n",
      " -0.116      -0.066      -0.05       -0.053      -0.179      -0.118\n",
      " -0.225      -0.138      -0.059      -0.193      -0.158      -0.31\n",
      " -0.171      -0.046      -0.111      -0.329      -0.273      -0.36\n",
      " -0.262      -0.282      -0.079      -0.299      -0.009      -0.28\n",
      " -0.56       -0.367      -0.092      -0.011      -0.021      -0.325\n",
      " -0.25       -0.042      -0.142      -0.246      -0.126      -0.082\n",
      " -0.302      -0.124      -0.57       -0.209      -0.214      -0.237\n",
      " -0.416      -0.012      -0.023      -0.297      -0.38       -0.258\n",
      " -0.353      -0.129      -0.267      -0.013      -0.14       -0.067\n",
      " -0.281      -0.343      -0.091      -0.068      -0.292      -0.151\n",
      " -0.3        -0.285      -0.155      -0.339      -0.076      -0.172\n",
      " -0.309      -0.34       -0.106      -0.24       -0.271      -0.133\n",
      " -0.306      -0.312      -0.174      -0.086      -0.218      -0.01\n",
      " -0.308      -0.375      -0.222      -0.058      -0.047      -0.238\n",
      " -0.073      -0.331      -0.585      -0.338      -0.207      -0.321\n",
      " -0.074      -0.491      -0.261      -0.295      -0.215      -0.157\n",
      " -0.256      -0.248      -0.255      -0.278      -0.089      -0.219\n",
      " -0.134      -0.026      -0.29       -0.587      -0.326      -0.284\n",
      " -0.328      -0.257      -0.23       -0.358      -0.422      -0.251\n",
      " -0.318      -0.252      -0.32       -0.317      -0.227      -0.346\n",
      " -0.856      -0.107      -0.286      -0.241      -0.283      -0.149\n",
      " -0.351      -0.305      -0.287      -0.057      -0.276      -0.76\n",
      " -0.335      -0.139      -0.344      -0.259      -0.274      -0.109\n",
      " -0.348      -0.062      -0.336      -0.019      -0.226      -0.294\n",
      " -0.314      -0.266      -0.296      -0.594      -0.403      -0.342\n",
      " -0.279      -0.029      -0.243      -0.33       -0.141      -0.231\n",
      " -0.293      -0.345      -0.391      -0.756      -0.265      -0.531\n",
      " -0.385      -0.632      -0.254      -0.352      -0.68       -0.445\n",
      " -0.368      -0.177      -0.372      -0.333      -0.247      -0.069\n",
      " -0.397      -0.205      -0.288      -0.242      -0.167      -0.378\n",
      " -0.223      -0.289      -0.332      -0.322      -0.409      -0.037\n",
      " -0.324      -0.239      -0.371      -0.301      -0.146      -0.191\n",
      " -0.249      -0.253      -0.206      -0.236      -0.307      -0.39\n",
      " -0.382      -0.337      -0.244      -0.199      -0.639      -0.386\n",
      " -0.929      -0.388      -0.313      -1.207      -0.615      -0.603\n",
      " -0.475      -0.497      -1.007      -0.836      -0.007      -0.334\n",
      " -0.392      -0.194      -0.812      -0.349      -0.413      -0.853\n",
      " -0.435      -0.37       -0.364      -0.377      -0.777      -0.319\n",
      " -0.357      -0.197      -0.034      -0.941      -0.245      -0.406\n",
      " -0.228      -0.323      -0.361      -0.354      -0.355      -0.62\n",
      " -0.439      -0.424      -0.407      -0.462      -0.711      -0.404\n",
      " -0.183      -0.315      -0.356      -0.402      -0.35       -0.381\n",
      " -0.373      -0.521      -0.745      -0.235      -0.539      -0.517\n",
      " -0.42       -0.572      -0.51       -0.277      -0.441      -0.528\n",
      " -0.341      -0.474      -0.515      -0.395      -0.363     ]\n",
      "Unique values for column 'koi_srad': [0.927 0.868 0.791 ... 2.054 0.318 7.824]\n",
      "Unique values for column 'koi_srad_err1': [0.105 0.233 0.201 ... 1.344 1.09  5.067]\n",
      "Unique values for column 'koi_srad_err2': [-0.061 -0.078 -0.067 ... -1.255 -0.632 -1.896]\n",
      "Unique values for column 'ra': [291.93423 297.00482 285.53461 ... 294.16489 296.76288 297.00977]\n",
      "Unique values for column 'dec': [48.141651 48.134129 48.28521  ... 47.176281 47.145142 47.121021]\n",
      "Unique values for column 'koi_kepmag': [15.347 15.436 15.597 ... 12.673 11.976 10.998]\n"
     ]
    }
   ],
   "source": [
    "# Print unique values for each column\n",
    "for column in kepler_data.columns:\n",
    "    unique_values = kepler_data[column].unique()\n",
    "    print(f\"Unique values for column '{column}': {unique_values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bb69341f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns present in the dataframe:\n",
      "Index(['kepid', 'kepoi_name', 'koi_disposition', 'koi_pdisposition',\n",
      "       'koi_score', 'koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co',\n",
      "       'koi_fpflag_ec', 'koi_period', 'koi_period_err1', 'koi_period_err2',\n",
      "       'koi_time0bk', 'koi_time0bk_err1', 'koi_time0bk_err2', 'koi_impact',\n",
      "       'koi_impact_err1', 'koi_impact_err2', 'koi_duration',\n",
      "       'koi_duration_err1', 'koi_duration_err2', 'koi_depth', 'koi_depth_err1',\n",
      "       'koi_depth_err2', 'koi_prad', 'koi_prad_err1', 'koi_prad_err2',\n",
      "       'koi_teq', 'koi_insol', 'koi_insol_err1', 'koi_insol_err2',\n",
      "       'koi_model_snr', 'koi_tce_plnt_num', 'koi_tce_delivname', 'koi_steff',\n",
      "       'koi_steff_err1', 'koi_steff_err2', 'koi_slogg', 'koi_slogg_err1',\n",
      "       'koi_slogg_err2', 'koi_srad', 'koi_srad_err1', 'koi_srad_err2', 'ra',\n",
      "       'dec', 'koi_kepmag'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print columns present in the dataframe\n",
    "print(\"Columns present in the dataframe:\")\n",
    "print(kepler_data.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbedb104",
   "metadata": {},
   "source": [
    "# 1.Why did you choose the particular algorithm?\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "71087c64",
   "metadata": {},
   "source": [
    "I chose the RandomForestClassifier algorithm because it's known for its ability to handle both classification tasks and datasets with a large number of features. Random forests are robust against overfitting and work well with both numerical and categorical data, making them suitable for the Kepler dataset, which includes a mix of numeric and categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fdff19",
   "metadata": {},
   "source": [
    "# 2.What are the different tuning methods used for the algorithm?\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6db07358",
   "metadata": {},
   "source": [
    "For tuning the RandomForestClassifier, I mainly focused on adjusting the hyperparameters that control the behavior of the model. Some common tuning methods include:\n",
    "\n",
    "Grid Search: Searching exhaustively over a specified hyperparameter grid to find the combination that yields the best performance.\n",
    "\n",
    "Random Search: Sampling hyperparameter combinations randomly from specified distributions, which can be more efficient than grid search.\n",
    "\n",
    "Cross-Validation: Using techniques like k-fold cross-validation to evaluate the model's performance across different subsets of the training data, helping to assess generalization performance and avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68c2d8a",
   "metadata": {},
   "source": [
    "# 3. Did you consider any other choice of algorithm?Why or why not?\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "76b01dfe",
   "metadata": {},
   "source": [
    "Yes, I did consider other algorithms before choosing RandomForestClassifier. Some alternatives include:\n",
    "Support Vector Machines (SVM): Suitable for binary classification tasks and effective in high-dimensional spaces.\n",
    "Gradient Boosting: Ensemble learning technique that builds multiple weak learners sequentially, often achieving high accuracy.\n",
    "Neural Networks: Deep learning models capable of learning complex patterns in data, although they require more computational resources and data preprocessing.\n",
    "However, I opted for RandomForestClassifier due to its simplicity, versatility, and generally good performance across a wide range of datasets.\n",
    "\n",
    "I also tried it with decsion tree and it was able to train and test the data sets well as i achieved a higher percent score which only took place due to dropping of a few columns and replacemnet with NULL.But working on a Rando forest would be way accurate for unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3a07543a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       484\n",
      "           1       1.00      1.00      1.00       490\n",
      "           2       1.00      1.00      1.00       939\n",
      "\n",
      "    accuracy                           1.00      1913\n",
      "   macro avg       1.00      1.00      1.00      1913\n",
      "weighted avg       1.00      1.00      1.00      1913\n",
      "\n",
      "Accuracy: 0.9989545216936748\n",
      "Accuracy percentage: 99.90%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Step 1: Load the Data\n",
    "csv_file_path = 'kepler_data-2.csv'\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Replace missing values with 'None'\n",
    "data.fillna('None', inplace=True)\n",
    "\n",
    "# Check if there are any samples left after preprocessing\n",
    "if data.empty:\n",
    "    print(\"Error: No samples left after preprocessing.\")\n",
    "    exit()\n",
    "\n",
    "# Encoding categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "data['koi_disposition'] = label_encoder.fit_transform(data['koi_disposition'])\n",
    "\n",
    "# Perform one-hot encoding for categorical features\n",
    "categorical_cols = ['kepoi_name', 'kepler_name', 'koi_pdisposition', 'koi_tce_delivname']\n",
    "for col in categorical_cols:\n",
    "    one_hot_encoded = pd.get_dummies(data[col], prefix=col)\n",
    "    data = pd.concat([data, one_hot_encoded], axis=1)\n",
    "    data.drop(col, axis=1, inplace=True)\n",
    "\n",
    "# Convert 'None' values to a numeric value\n",
    "data.replace('None', -1, inplace=True)\n",
    "\n",
    "# Step 2: Split the Data\n",
    "X = data.drop(columns=['koi_disposition'])\n",
    "y = data['koi_disposition']\n",
    "\n",
    "# Step 3: Split the Data into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Model Selection and Training\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Model Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Calculate and print accuracy percentage\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Accuracy percentage: {:.2f}%\".format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d46d9b",
   "metadata": {},
   "source": [
    "# 4.What is the accuracy?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c1b5df57",
   "metadata": {},
   "source": [
    "Random forest- 98.43%\n",
    "Decison Tree- 99.90%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c0b883",
   "metadata": {},
   "source": [
    "# 5. What are the different types of metrics that can be used to evaluate the model?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "82c46f9c",
   "metadata": {},
   "source": [
    "Precision, Recall, and F1 Score: Useful for evaluating the balance between false positives and false negatives.\n",
    "\n",
    "Confusion Matrix: Provides a more detailed breakdown of the model's predictions across different classes.\n",
    "\n",
    "ROC Curve and AUC Score\n",
    "\n",
    "All these help make informed decisions about its deployment and further optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c9ee58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
